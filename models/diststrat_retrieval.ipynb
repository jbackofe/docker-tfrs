{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X80i_girFR2o"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:13.579873Z",
     "iopub.status.busy": "2022-12-14T12:26:13.579265Z",
     "iopub.status.idle": "2022-12-14T12:26:13.582988Z",
     "shell.execute_reply": "2022-12-14T12:26:13.582435Z"
    },
    "id": "bB8gHCR3FVC0"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z17OmgavQfp4"
   },
   "source": [
    "# Recommending movies: retrieval with distribution strategy\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/diststrat_retrieval\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/diststrat_retrieval.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/diststrat_retrieval.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/diststrat_retrieval.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCeYA79m1DEX"
   },
   "source": [
    "In this tutorial, we're going to train the same retrieval model as we did in the [basic retrieval](basic_retrieval) tutorial, but with distribution strategy.\n",
    "\n",
    "We're going to:\n",
    "\n",
    "1. Get our data and split it into a training and test set.\n",
    "2. Set up two virtual GPUs and TensorFlow MirroredStrategy.\n",
    "3. Implement a retrieval model using MirroredStrategy.\n",
    "4. Fit it with MirrorredStrategy and evaluate it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sawo1x8kQk9b"
   },
   "source": [
    "## Imports\n",
    "\n",
    "\n",
    "Let's first get our imports out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:13.586297Z",
     "iopub.status.busy": "2022-12-14T12:26:13.585837Z",
     "iopub.status.idle": "2022-12-14T12:26:17.026218Z",
     "shell.execute_reply": "2022-12-14T12:26:17.025238Z"
    },
    "id": "0vJOdh9WbTpd"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-recommenders\n",
    "# !pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:17.030286Z",
     "iopub.status.busy": "2022-12-14T12:26:17.030009Z",
     "iopub.status.idle": "2022-12-14T12:26:19.371050Z",
     "shell.execute_reply": "2022-12-14T12:26:19.370353Z"
    },
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 01:40:32.657212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-28 01:40:32.751631: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-28 01:40:32.754489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-28 01:40:32.754500: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-28 01:40:33.162392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-28 01:40:33.162460: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-28 01:40:33.162464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:19.374959Z",
     "iopub.status.busy": "2022-12-14T12:26:19.374587Z",
     "iopub.status.idle": "2022-12-14T12:26:19.386884Z",
     "shell.execute_reply": "2022-12-14T12:26:19.386227Z"
    },
    "id": "BxQ_hy7xPH3N"
   },
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "We prepare the dataset in exactly the same way as we do in the [basic retrieval](basic_retrieval) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:19.390382Z",
     "iopub.status.busy": "2022-12-14T12:26:19.389928Z",
     "iopub.status.idle": "2022-12-14T12:26:28.419722Z",
     "shell.execute_reply": "2022-12-14T12:26:28.418835Z"
    },
    "id": "aaQhqcLGP0jL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n",
      "{'movie_genres': array([4]),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 01:40:33.825767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-28 01:40:33.825797: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-28 01:40:33.825812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aa4f961c358e): /proc/driver/nvidia/version does not exist\n",
      "2022-12-28 01:40:33.826092: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-28 01:40:33.959474: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-12-28 01:40:33.993161: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
       "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
       "       b'2 Days in the Valley (1996)',\n",
       "       b'20,000 Leagues Under the Sea (1954)',\n",
       "       b'2001: A Space Odyssey (1968)',\n",
       "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       "       b'39 Steps, The (1935)'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)\n",
    "\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Qk-r3dNvreA"
   },
   "source": [
    "## Set up two virtual GPUs\n",
    "\n",
    "If you have not added GPU accelerators to your Colab, please disconnect the Colab runtime and do it now. We need the GPU to run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:28.423616Z",
     "iopub.status.busy": "2022-12-14T12:26:28.422943Z",
     "iopub.status.idle": "2022-12-14T12:26:29.512597Z",
     "shell.execute_reply": "2022-12-14T12:26:29.511720Z"
    },
    "id": "09AZOFL8wNVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    # Create 2 virtual GPUs with 1GB memory each\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n",
    "             tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCi-seR86qqa"
   },
   "source": [
    "## Implementing a model\n",
    "\n",
    "We implement the user_model, movie_model, metrics and task in the same way as we do in the [basic retrieval](basic_retrieval) tutorial, but we wrap them in the distribution strategy scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:29.516245Z",
     "iopub.status.busy": "2022-12-14T12:26:29.515706Z",
     "iopub.status.idle": "2022-12-14T12:26:29.711407Z",
     "shell.execute_reply": "2022-12-14T12:26:29.710560Z"
    },
    "id": "kHQZJEhXP93N"
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "with strategy.scope():\n",
    "    user_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        # We add an additional embedding to account for unknown tokens.\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    movie_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    metrics = tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128).map(movie_model)\n",
    "    )\n",
    "\n",
    "    task = tfrs.tasks.Retrieval(\n",
    "        metrics=metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZUFeSlWRHGx"
   },
   "source": [
    "We can now put it all together into a model. This is exactly the same as in the [basic retrieval](basic_retrieval) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:29.715155Z",
     "iopub.status.busy": "2022-12-14T12:26:29.714513Z",
     "iopub.status.idle": "2022-12-14T12:26:29.719912Z",
     "shell.execute_reply": "2022-12-14T12:26:29.719149Z"
    },
    "id": "8n7c5CHFp0ow"
   },
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, movie_model):\n",
    "        super().__init__()\n",
    "        self.movie_model: tf.keras.Model = movie_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDN_LJGlnRGo"
   },
   "source": [
    "## Fitting and evaluating\n",
    "\n",
    "Now we instantiate and compile the model within the distribution strategy scope.\n",
    "\n",
    "Note that we are using Adam optimizer here instead of Adagrad as in the [basic retrieval](basic_ranking) tutorial since Adagrad is not supported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:29.723378Z",
     "iopub.status.busy": "2022-12-14T12:26:29.722754Z",
     "iopub.status.idle": "2022-12-14T12:26:29.756841Z",
     "shell.execute_reply": "2022-12-14T12:26:29.756079Z"
    },
    "id": "aW63YaqP2wCf"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = MovielensModel(user_model, movie_model)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nma0vc2XdN5g"
   },
   "source": [
    "Then shuffle, batch, and cache the training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:29.760508Z",
     "iopub.status.busy": "2022-12-14T12:26:29.759887Z",
     "iopub.status.idle": "2022-12-14T12:26:29.769620Z",
     "shell.execute_reply": "2022-12-14T12:26:29.768856Z"
    },
    "id": "53QJwY1gUnfv"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8mHTxKAdTJO"
   },
   "source": [
    "Then train the  model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:29.773215Z",
     "iopub.status.busy": "2022-12-14T12:26:29.772549Z",
     "iopub.status.idle": "2022-12-14T12:26:46.776219Z",
     "shell.execute_reply": "2022-12-14T12:26:46.775558Z"
    },
    "id": "ZxPntlT8EFOZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 01:40:37.383670: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:549] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
      "2022-12-28 01:40:37.429035: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 8s 322ms/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 9.1250e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0028 - factorized_top_k/top_50_categorical_accuracy: 0.0257 - factorized_top_k/top_100_categorical_accuracy: 0.0638 - loss: 70011.0305 - regularization_loss: 0.0000e+00 - total_loss: 70011.0305\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 3s 323ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0125 - factorized_top_k/top_10_categorical_accuracy: 0.0269 - factorized_top_k/top_50_categorical_accuracy: 0.1285 - factorized_top_k/top_100_categorical_accuracy: 0.2343 - loss: 66665.7699 - regularization_loss: 0.0000e+00 - total_loss: 66665.7699\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 4s 348ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0191 - factorized_top_k/top_10_categorical_accuracy: 0.0408 - factorized_top_k/top_50_categorical_accuracy: 0.1810 - factorized_top_k/top_100_categorical_accuracy: 0.3095 - loss: 64813.3075 - regularization_loss: 0.0000e+00 - total_loss: 64813.3075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efff844a320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsluR8audV9W"
   },
   "source": [
    "You can see from the training log that TFRS is making use of both virtual GPUs.\n",
    "\n",
    "Finally, we can evaluate our model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:26:46.779682Z",
     "iopub.status.busy": "2022-12-14T12:26:46.779158Z",
     "iopub.status.idle": "2022-12-14T12:26:51.697984Z",
     "shell.execute_reply": "2022-12-14T12:26:51.697196Z"
    },
    "id": "W-zu6HLODNeI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 01:40:52.598339: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:549] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 138ms/step - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0013 - factorized_top_k/top_10_categorical_accuracy: 0.0049 - factorized_top_k/top_50_categorical_accuracy: 0.0609 - factorized_top_k/top_100_categorical_accuracy: 0.1484 - loss: 32366.3665 - regularization_loss: 0.0000e+00 - total_loss: 32366.3665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 9.999999747378752e-05,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0013000000035390258,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.004900000058114529,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.0608999989926815,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.14839999377727509,\n",
       " 'loss': 29347.8203125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 29347.8203125}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKZyP9A1dxit"
   },
   "source": [
    "This concludes the retrieval with distribution strategy tutorial."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "diststrat_retrieval.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
